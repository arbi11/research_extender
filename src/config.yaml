# Research Extension System Configuration

# LLM Configuration
llm:
  # model: "x-ai/grok-4-fast:free" 
  model: "openai/gpt-5"
  # model: "alibaba/tongyi-deepresearch-30b-a3b"
  # model: "x-ai/grok-code-fast-1"
  # model: "google/gemini-2.5-flash"
  temperature: 0
  max_tokens: 4000
  base_url: "https://openrouter.ai/api/v1"

# Embedding Configuration
embedding:
  model: "Qwen/Qwen3-Embedding-0.6B"
  # model: "sentence-transformers/all-MiniLM-L6-v2" # 384, 5000
  dimension: 1024
  max_token_size: 32768
  normalize: true
  convert_to_numpy: true

# Directory Configuration
directories:
  working_dir: "./research_graph_gpt5_qwen3_0_6b"
  output_dir: "./research_extensions"

# Code File Extensions
code_files:
  supported_extensions:
    - "*.py"
    - "*.cpp"
    - "*.c"
    - "*.h"
    - "*.js"
    - "*.ts"
    - "*.java"

# Processing Configuration
processing:
  similarity_threshold: 2  # Minimum similarity score for code-equation mapping
  gap_priorities:
    high: 3
    medium: 2
    low: 1
