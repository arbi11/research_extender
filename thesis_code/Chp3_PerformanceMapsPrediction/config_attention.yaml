# Attention Model Configuration for Efficiency Map Prediction

# Model Architecture
model:
  architecture: "attention"
  bidirectional: true
  gru_units: 128
  dense_units: 64
  dropout: 0.5
  input_dim: 14

# Training Configuration
training:
  epochs: 30
  batch_size: 32
  learning_rate: 0.001
  optimizer: "nadam"

# Data Configuration
data:
  data_path: "path/to/your/data"  # Update this path to your data directory
  data_type: "efficiency"  # "efficiency" or "powerfactor"
  normalization: "divide_by_100"  # Target values are divided by 100

# Logging Configuration
logging:
  log_dir: "runs/attention_training"
  save_model: true
  model_save_path: "models/attention_model"

# Evaluation Configuration
evaluation:
  eval_frequency: 1  # Evaluate every N epochs
  save_predictions: true
  confusion_matrix: true
